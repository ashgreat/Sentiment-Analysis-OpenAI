{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531c8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import constants # This is a Python file constants.py and contains the OpenAI API key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c90d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=constants.OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "173b5d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews from CSV file...\n",
      "Found 100 reviews to process...\n",
      "Processing review 1/100...\n",
      "Processing review 2/100...\n",
      "Processing review 3/100...\n",
      "Processing review 4/100...\n",
      "Processing review 5/100...\n",
      "Processing review 6/100...\n",
      "Processing review 7/100...\n",
      "Processing review 8/100...\n",
      "Processing review 9/100...\n",
      "Processing review 10/100...\n",
      "Processing review 11/100...\n",
      "Processing review 12/100...\n",
      "Processing review 13/100...\n",
      "Processing review 14/100...\n",
      "Processing review 15/100...\n",
      "Processing review 16/100...\n",
      "Processing review 17/100...\n",
      "Processing review 18/100...\n",
      "Processing review 19/100...\n",
      "Processing review 20/100...\n",
      "Processing review 21/100...\n",
      "Processing review 22/100...\n",
      "Processing review 23/100...\n",
      "Processing review 24/100...\n",
      "Processing review 25/100...\n",
      "Processing review 26/100...\n",
      "Processing review 27/100...\n",
      "Processing review 28/100...\n",
      "Processing review 29/100...\n",
      "Processing review 30/100...\n",
      "Processing review 31/100...\n",
      "Processing review 32/100...\n",
      "Processing review 33/100...\n",
      "Processing review 34/100...\n",
      "Processing review 35/100...\n",
      "Processing review 36/100...\n",
      "Processing review 37/100...\n",
      "Processing review 38/100...\n",
      "Processing review 39/100...\n",
      "Processing review 40/100...\n",
      "Processing review 41/100...\n",
      "Processing review 42/100...\n",
      "Processing review 43/100...\n",
      "Processing review 44/100...\n",
      "Processing review 45/100...\n",
      "Processing review 46/100...\n",
      "Processing review 47/100...\n",
      "Processing review 48/100...\n",
      "Processing review 49/100...\n",
      "Processing review 50/100...\n",
      "Processing review 51/100...\n",
      "Processing review 52/100...\n",
      "Processing review 53/100...\n",
      "Processing review 54/100...\n",
      "Processing review 55/100...\n",
      "Processing review 56/100...\n",
      "Processing review 57/100...\n",
      "Processing review 58/100...\n",
      "Processing review 59/100...\n",
      "Processing review 60/100...\n",
      "Processing review 61/100...\n",
      "Processing review 62/100...\n",
      "Processing review 63/100...\n",
      "Processing review 64/100...\n",
      "Processing review 65/100...\n",
      "Processing review 66/100...\n",
      "Processing review 67/100...\n",
      "Processing review 68/100...\n",
      "Processing review 69/100...\n",
      "Processing review 70/100...\n",
      "Processing review 71/100...\n",
      "Processing review 72/100...\n",
      "Processing review 73/100...\n",
      "Processing review 74/100...\n",
      "Processing review 75/100...\n",
      "Processing review 76/100...\n",
      "Processing review 77/100...\n",
      "Processing review 78/100...\n",
      "Processing review 79/100...\n",
      "Processing review 80/100...\n",
      "Processing review 81/100...\n",
      "Processing review 82/100...\n",
      "Processing review 83/100...\n",
      "Processing review 84/100...\n",
      "Processing review 85/100...\n",
      "Processing review 86/100...\n",
      "Processing review 87/100...\n",
      "Processing review 88/100...\n",
      "Processing review 89/100...\n",
      "Processing review 90/100...\n",
      "Processing review 91/100...\n",
      "Processing review 92/100...\n",
      "Processing review 93/100...\n",
      "Processing review 94/100...\n",
      "Processing review 95/100...\n",
      "Processing review 96/100...\n",
      "Processing review 97/100...\n",
      "Processing review 98/100...\n",
      "Processing review 99/100...\n",
      "Processing review 100/100...\n",
      "Converting analysis results to DataFrame...\n",
      "Combining original data with analysis results...\n",
      "Saving results to Data/reviews_100_analyzed.csv...\n",
      "Analysis complete!\n",
      "Results saved to: Data/reviews_100_analyzed.csv\n",
      "Total reviews processed: 100\n",
      "\n",
      "--- Analysis Summary ---\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "positive    51\n",
      "negative    47\n",
      "neutral      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top products identified:\n",
      "product\n",
      "book         39\n",
      "N/A          15\n",
      "movie         4\n",
      "shapewear     3\n",
      "pants         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top brands identified:\n",
      "brand\n",
      "N/A                  78\n",
      "Squeem                3\n",
      "Sony                  2\n",
      "Patricia Cornwell     2\n",
      "JVC                   2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Sample of Enhanced Data ---\n",
      "   polarity                                              title  \\\n",
      "0         2                                           Great CD   \n",
      "1         2  One of the best game music soundtracks - for a...   \n",
      "2         1                   Batteries died within a year ...   \n",
      "3         2              works fine, but Maha Energy is better   \n",
      "4         2                       Great for the non-audiophile   \n",
      "\n",
      "                                                text sentiment  happiness  \\\n",
      "0  My lovely Pat has one of the GREAT voices of h...  positive          5   \n",
      "1  Despite the fact that I have only played a sma...  positive          4   \n",
      "2  I bought this charger in Jul 2003 and it worke...  negative          1   \n",
      "3  Check out Maha Energy's website. Their Powerex...   neutral          2   \n",
      "4  Reviewed quite a bit of the combo players and ...  positive          4   \n",
      "\n",
      "   sadness  anger  fear  surprise  disgust  neutral_emotion       product  \\\n",
      "0        0      0     0         1        0                0            CD   \n",
      "1        3      0     0         2        1                0    soundtrack   \n",
      "2        4      3     0         1        2                0       charger   \n",
      "3        0      0     0         1        0                3       charger   \n",
      "4        1      0     0         2        0                1  combo player   \n",
      "\n",
      "  brand        aspect_1 aspect_1_sentiment          aspect_2  \\\n",
      "0   N/A          vocals           positive            lyrics   \n",
      "1   N/A   music quality           positive  emotional impact   \n",
      "2   N/A    battery life           negative            design   \n",
      "3   N/A  charging speed           positive  battery capacity   \n",
      "4   N/A   build quality           positive     ease of setup   \n",
      "\n",
      "  aspect_2_sentiment                        aspect_3 aspect_3_sentiment  \n",
      "0           positive               overall enjoyment           positive  \n",
      "1           positive                  guitar effects           negative  \n",
      "2           positive                 value for money           negative  \n",
      "3           positive       comparison to Maha Energy           negative  \n",
      "4           positive  resolution and special effects           positive  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def analyze_review(title: str, text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze a single review using OpenAI API for sentiment, emotions, aspects, and product identification.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following Amazon review and provide a comprehensive analysis in JSON format.\n",
    "\n",
    "    Review Title: {title}\n",
    "    Review Text: {text}\n",
    "\n",
    "    Please provide the analysis in the following JSON structure:\n",
    "    {{\n",
    "        \"sentiment\": \"positive/negative/neutral\",\n",
    "        \"emotions\": {{\n",
    "            \"happiness\": 0-5,\n",
    "            \"sadness\": 0-5,\n",
    "            \"anger\": 0-5,\n",
    "            \"fear\": 0-5,\n",
    "            \"surprise\": 0-5,\n",
    "            \"disgust\": 0-5,\n",
    "            \"neutral\": 0-5\n",
    "        }},\n",
    "        \"aspects\": [\n",
    "            {{\n",
    "                \"aspect\": \"aspect name\",\n",
    "                \"sentiment\": \"positive/negative/neutral\"\n",
    "            }},\n",
    "            {{\n",
    "                \"aspect\": \"aspect name\", \n",
    "                \"sentiment\": \"positive/negative/neutral\"\n",
    "            }},\n",
    "            {{\n",
    "                \"aspect\": \"aspect name\",\n",
    "                \"sentiment\": \"positive/negative/neutral\"\n",
    "            }}\n",
    "        ],\n",
    "        \"product\": \"product type or N/A\",\n",
    "        \"brand\": \"brand name or N/A\"\n",
    "    }}\n",
    "\n",
    "    Instructions:\n",
    "    1. Sentiment: Classify overall sentiment as positive, negative, or neutral\n",
    "    2. Emotions: Rate each emotion on scale 0-5 (0=absent, 1=somewhat, 5=very much)\n",
    "    3. Aspects: Identify up to 3 key aspects mentioned (e.g., \"battery life\", \"screen quality\", \"price\") and their sentiment\n",
    "    4. Product: Identify the product category (e.g., \"laptop\", \"smartphone\", \"headphones\") or \"N/A\"\n",
    "    5. Brand: Identify the brand name or \"N/A\"\n",
    "    \n",
    "    Return only valid JSON without any additional text or formatting.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",  # Using gpt-4o-mini for cost efficiency\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert at analyzing product reviews. Always respond with valid JSON only.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_output_tokens=500\n",
    "        )\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        analysis = json.loads(response.output_text)\n",
    "        return analysis\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error: {e}\")\n",
    "        # Return a default structure if JSON parsing fails\n",
    "        return {\n",
    "            \"sentiment\": \"neutral\",\n",
    "            \"emotions\": {\"happiness\": 0, \"sadness\": 0, \"anger\": 0, \"fear\": 0, \"surprise\": 0, \"disgust\": 0, \"neutral\": 3},\n",
    "            \"aspects\": [],\n",
    "            \"product\": \"N/A\",\n",
    "            \"brand\": \"N/A\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {e}\")\n",
    "        return {\n",
    "            \"sentiment\": \"neutral\",\n",
    "            \"emotions\": {\"happiness\": 0, \"sadness\": 0, \"anger\": 0, \"fear\": 0, \"surprise\": 0, \"disgust\": 0, \"neutral\": 3},\n",
    "            \"aspects\": [],\n",
    "            \"product\": \"N/A\",\n",
    "            \"brand\": \"N/A\"\n",
    "        }\n",
    "\n",
    "def process_reviews_file(input_file: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Process all reviews in the CSV file and save the enhanced results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the original CSV file\n",
    "    print(\"Loading reviews from CSV file...\")\n",
    "    df_original = pd.read_csv(input_file)\n",
    "    \n",
    "    # Validate required columns\n",
    "    if 'title' not in df_original.columns or 'text' not in df_original.columns:\n",
    "        raise ValueError(\"CSV file must contain 'title' and 'text' columns\")\n",
    "    \n",
    "    print(f\"Found {len(df_original)} reviews to process...\")\n",
    "    \n",
    "    # Initialize lists to store analysis results\n",
    "    analysis_results = []\n",
    "    \n",
    "    # Process each review\n",
    "    for idx, row in df_original.iterrows():\n",
    "        print(f\"Processing review {idx + 1}/{len(df_original)}...\")\n",
    "        \n",
    "        # Analyze the review\n",
    "        analysis = analyze_review(row['title'], row['text'])\n",
    "        analysis_results.append(analysis)\n",
    "        \n",
    "        # Add a small delay to avoid rate limiting\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Convert analysis results to DataFrame\n",
    "    print(\"Converting analysis results to DataFrame...\")\n",
    "    \n",
    "    # Extract data for DataFrame\n",
    "    df_analysis_data = []\n",
    "    for analysis in analysis_results:\n",
    "        row_data = {\n",
    "            'sentiment': analysis['sentiment'],\n",
    "            'happiness': analysis['emotions']['happiness'],\n",
    "            'sadness': analysis['emotions']['sadness'],\n",
    "            'anger': analysis['emotions']['anger'],\n",
    "            'fear': analysis['emotions']['fear'],\n",
    "            'surprise': analysis['emotions']['surprise'],\n",
    "            'disgust': analysis['emotions']['disgust'],\n",
    "            'neutral_emotion': analysis['emotions']['neutral'],\n",
    "            'product': analysis['product'],\n",
    "            'brand': analysis['brand']\n",
    "        }\n",
    "        \n",
    "        # Add up to 3 aspects\n",
    "        for i in range(3):\n",
    "            if i < len(analysis['aspects']):\n",
    "                row_data[f'aspect_{i+1}'] = analysis['aspects'][i]['aspect']\n",
    "                row_data[f'aspect_{i+1}_sentiment'] = analysis['aspects'][i]['sentiment']\n",
    "            else:\n",
    "                row_data[f'aspect_{i+1}'] = 'N/A'\n",
    "                row_data[f'aspect_{i+1}_sentiment'] = 'N/A'\n",
    "        \n",
    "        df_analysis_data.append(row_data)\n",
    "    \n",
    "    # Create DataFrame from analysis results\n",
    "    df_analysis = pd.DataFrame(df_analysis_data)\n",
    "    \n",
    "    # Combine original DataFrame with analysis results\n",
    "    print(\"Combining original data with analysis results...\")\n",
    "    df_combined = pd.concat([df_original, df_analysis], axis=1)\n",
    "    \n",
    "    # Save to new CSV file\n",
    "    print(f\"Saving results to {output_file}...\")\n",
    "    df_combined.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(\"Analysis complete!\")\n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    print(f\"Total reviews processed: {len(df_combined)}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\n--- Analysis Summary ---\")\n",
    "    print(f\"Sentiment distribution:\")\n",
    "    print(df_combined['sentiment'].value_counts())\n",
    "    print(f\"\\nTop products identified:\")\n",
    "    print(df_combined['product'].value_counts().head())\n",
    "    print(f\"\\nTop brands identified:\")\n",
    "    print(df_combined['brand'].value_counts().head())\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # File paths\n",
    "    input_file = \"Data/reviews_100.csv\"\n",
    "    output_file = \"Data/reviews_100_analyzed.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Process the reviews\n",
    "        df_result = process_reviews_file(input_file, output_file)\n",
    "        \n",
    "        # Display first few rows of the result\n",
    "        print(\"\\n--- Sample of Enhanced Data ---\")\n",
    "        print(df_result.head())\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {input_file}\")\n",
    "        print(\"Please make sure the file exists in the current directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025 (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
